# CAS - 동기화와 원자적 연산

## 1. 원자적 연산(Atomic Operation)

### 1.1. 원자적 연산이란?

- **더 이상 나눌 수 없는 하나의 단위**로 수행되는 연산을 의미한다.
- 이는 연산이 실행되는 중간에 다른 스레드가 끼어들 수 없으며, **'모두 실행되거나, 아예 실행되지 않거나(All-or-Nothing)'** 를 보장한다.

### 1.2. 원자적 연산의 예시

- **원자적인 연산**: `i = 10;`과 같은 단순 대입 연산은 원자적이다. 이는 값을 변수에 대입하는 **단 하나의 기계어 명령**으로 실행되기 때문이다.
- **원자적이 아닌 연산**: `i++;` 또는 `i = i + 1;`과 같은 증감 연산은 원자적이 아니다. 이 연산은 내부적으로 `i의 값을 읽는다`, `값에 1을 더한다`, `결과를 i에 다시 쓴다` 의 세 단계로 나뉘어 실행되기 때문이다. 각 단계 사이에 다른 스레드가 개입할 수 있다.

### 1.3. 동시성 문제와의 관계

- 원자적 연산은 **그 자체로 동시성 문제로부터 안전**하다.
- 하지만, 원자적이 아닌 연산을 공유 자원에 대해 수행할 경우에는, **`synchronized`나 `Lock` 등을 사용**하여 **임계 영역(Critical Section)** 으로 만들어 반드시 보호해야 한다.

## 2. 락 기반 방식의 문제점

- 공유 데이터를 보호하기 위해 **락(Lock)** 을 사용하는 방식이 있다. 여기서 말하는 락은 `synchronized`나 `ReentrantLock`과 같은 기술을 의미한다.
- 락은 특정 자원을 보호하기 위해 스레드의 접근을 제한하며, 한 스레드가 락을 점유하고 있는 동안 다른 스레드들은 **락이 해제될 때까지 대기**해야 한다.
- 락 기반 방식은 **락을 획득하고 해제하는 과정에서 시간**이 소요되는 단점이 있다.
  1.  락이 있는지 확인한다.
  2.  락을 획득하고 임계 영역에 들어간다.
  3.  작업을 수행한다.
  4.  락을 반납한다.
- 이처럼 락을 획득하고 반납하는 과정이 반복되므로, 구현은 직관적이지만 **상대적으로 무거운 방식**이라고 할 수 있다.

## 3. CAS (Compare-And-Swap)

- 락 기반 방식의 문제점을 해결하기 위해, **락을 사용하지 않고 원자적 연산을 수행**하는 방법을 **CAS(Compare-And-Swap, Compare-And-Set)** 연산이라고 한다.
- 이 방법은 락을 사용하지 않으므로 **락-프리(Lock-Free)** 기법이라고도 한다.
- CAS 연산은 락을 완전히 대체하는 것이 아니다. 기본적으로는 락을 사용하고, 특별한 경우에만 CAS를 적용하는 것이 일반적이다.
- 자바는 `java.util.concurrent.atomic` 패키지의 클래스들이 제공하는 **`compareAndSet()`** 메서드를 통해 CAS 연산을 지원한다.

### 3.1. compareAndSet()

- `compareAndSet(expectedValue, newValue)` 메서드는 '현재 값이 **기대하는 값(expected value)과 같다면, 새로운 값(new value)으로 변경**하라'는 매우 단순한 연산이다.
  - 만약 현재 값이 기대 값과 같다면, 값을 새로운 값으로 변경하고 `true`를 반환한다.
  - 만약 현재 값이 기대 값과 다르다면, 아무것도 변경하지 않고 `false`를 반환한다.
- 이 **'비교하고 변경하는' 과정 전체가 원자적으로 실행**된다는 것이 핵심이다.
- 소프트웨어 관점에서는 이 연산이 **값을 확인하는 단계**와 **값을 변경하는 단계**로 나뉘는 것처럼 보이지만, 실제로는 원자적으로 동작한다.

### 3.2. CPU 하드웨어의 지원

- CAS 연산은 소프트웨어 수준에서는 원자적이 아닌 연산을, **CPU 하드웨어 차원에서 하나의 원자적 연산으로 묶어서 제공**하는 기능이다.
- 즉, 소프트웨어가 아닌 **하드웨어가 직접 지원**하는 기능이며, 대부분의 현대 CPU는 CAS를 위한 명령어를 제공한다.
- CPU는 **'값을 확인하는 과정'과 '값을 변경하는 과정'을 하나의 원자적인 명령어로 만들어**, 중간에 다른 스레드가 개입할 수 없도록 한다.
- CPU는 이 두 과정 사이에 다른 스레드가 해당 메모리 주소의 값을 변경하지 못하도록 하드웨어 수준에서 막는다. 이 과정은 CPU 입장에서 보면 아주 찰나의 순간에 일어나므로, 락을 사용하는 방식보다 **성능상 이점**이 크다.

### 3.3. CAS 동작 방식

- CAS는 락을 사용하는 대신, 다른 스레드와의 **충돌이 발생하면 루프를 돌며 재시도하는 방식**을 사용한다.
- 동작 방식은 다음과 같다.
  1.  현재 변수의 값을 읽어온다.
  2.  값을 변경하기 전에, CAS 연산을 사용해서 **현재 값이 이전에 읽은 값과 동일한지 확인**한다.
  3.  값이 동일하다면, 새로운 값을 변수에 저장하고 연산을 종료한다.
  4.  값이 동일하지 않다면, 다른 스레드가 먼저 값을 변경한 것이므로 **처음부터 다시 과정을 반복**한다.
- 이처럼 충돌이 발생할 때마다 재시도하므로, 결과적으로 **락 없이도 데이터를 안전하게 변경**할 수 있다.
- CAS 방식은 **충돌이 드물게 발생하는 환경**에서, 스레드가 락을 얻기 위해 대기하지 않으므로 **대기 시간과 문맥 교환(Context Switching) 오버헤드가 줄어들어** 높은 성능을 발휘할 수 있다.
- 하지만, **충돌이 빈번하게 발생하는 환경**에서는 오히려 성능 문제가 발생할 수 있다. CAS 연산이 계속 실패하고 재시도 루프를 반복하게 되므로, **CPU 자원을 많이 소모하여 성능 저하**가 발생할 수 있다.

## 4. CAS와 LOCK 방식의 비교

### 4.1. 락 방식

- **비관적(Pessimistic) 접근법**이다.
- 데이터에 접근하기 전에 **항상 락(Lock)을 획득**하여, 다른 스레드의 접근을 원천적으로 막는 방식이다.
- 이는 **다른 스레드가 항상 방해할 것**이라고 비관적으로 가정하는 것이다.

### 4.2. CAS 방식

- **낙관적(Optimistic) 접근법**이다.
- 락을 사용하지 않고 **데이터에 우선 접근**한 뒤, 충돌이 발생하면 그때 재시도하는 방식이다.
- 이는 **대부분의 경우 충돌이 없을 것**이라고 낙관적으로 가정하는 것이다.
- 간단한 CPU 연산은 매우 빠르게 처리되므로 **충돌이 자주 발생하지 않는다**. 충돌이 일어나기도 전에 연산이 완료되는 경우가 더 많기 때문이다.
- 따라서 간단한 CPU 연산에는 **락 방식보다 CAS 방식이 더 유리**하다.

## 5. CAS 락 구현

- `synchronized`나 `Lock` 없이, **CAS를 이용해서 직접 락(Lock)을 구현**할 수도 있다.
- CAS를 사용한 원자적 연산 덕분에, **무거운 동기화 작업 없이 매우 가벼운 락**을 만들 수 있다.
- `synchronized`나 `Lock`을 사용하면 락을 획득하지 못한 스레드가 `BLOCKED`나 `WAITING` 상태로 전환되고, 이를 다시 깨우는 복잡한 과정이 필요하다.
- 반면, CAS를 활용한 락은 실제 락이 있는 것이 아니라 **단순히 `while` 문을 반복**할 뿐이다. 따라서 대기하는 스레드도 **`RUNNABLE` 상태를 유지하면서 가볍고 빠르게 작동**할 수 있다.

### 5.1 CAS 락의 장단점

- 이 방식은 락을 기다리는 스레드가 BLOCKED, WAITING 상태로 빠지지는 않지만, RUNNABLE 상태로 락을 획득할 떄까지 while문을 반복하는 문제가 있따. 따라서 락을 기다리는 슬드가 CPU를 계속 사용하면서 대기하는 것이다.
- 동기화 락을 사ㅛㅇ하면 RUNNABLE 상태의 스레드가 BLOCKED, WAITING 상태에서 다시 RUNNABLE 상태로 이동한다. 이 사이에 CPU 자원을 거의 사용하지 않을 수 있다.
- 그래서 동기화 락을 사용하는 방식보다 스레드를 RUNNABLE 살려둔 상태에서 계속 락 획득을 반복 체크하는 것이 더 효율적인 경우에 이런 방식을 사용해야 한다. 이 방식은 스레드의 상태가 변경되지 않기 때문에 매우 락을 빠르게 획득하고, 또 바로 실행할 수 있다는 장점이 있다.
- 즉, 안전한 임계 영역이 필요하지만, 연산이 길지 않고 매우매우매우 짧게 끝날 때 사용해야 한다. 예를 들어 숫자 값의 증가, 자료 구조의 데이터 추가와 같이 CPU 사이클이 금방 끝나는 연산에 사용하면 효과적이다.
- 반면에 데이터베이스의 결과를 대기한다거나, 다른 서버의 요청을 기다린다는 것처럼 오래 걸리는 작업에 사용하면 CPU를 계속 사용하며 기다리는 최악의 결과가 나올 수 있다.

### 5.1. CAS 락의 장단점

- 이 방식은, 락을 기다리는 스레드가 `BLOCKED`나 `WAITING` 상태로 전환되지 않고 **`RUNNABLE` 상태로 `while` 문을 계속 반복**한다는 점이다. 즉, **CPU 자원을 계속 사용하면서 대기**하는 것이다.
- 반면, `synchronized`와 같은 동기화 락은 대기하는 동안 CPU 자원을 거의 사용하지 않는다.
- 따라서 CAS 락은, 스레드 상태를 전환하는 비용보다 **`RUNNABLE` 상태로 계속 락 획득을 시도하는 것이 더 효율적인 경우에만 사용**해야 한다.
- 즉, 임계 영역의 **연산이 매우 짧게 끝날 때 사용해야 효과적**이다. 예를 들어, 숫자 값을 증가시키는 것처럼 CPU 사이클이 금방 끝나는 연산이 이에 해당한다.
- 반대로, 데이터베이스 조회나 다른 서버의 응답을 기다리는 것처럼 **오래 걸리는 작업에 사용하면, CPU 자원만 낭비하는 최악의 결과**가 나올 수 있다.

## 6. 스핀 락 (Spin Lock)

- 스레드가 락이 해제되기를 기다리며 **반복문을 통해 계속해서 락 획득을 확인하는 모습**이, 마치 제자리에서 **회전(spin)하는 것처럼 보인다**고 해서 이러한 방식을 **스핀 락(Spin Lock)** 이라고 부른다.
- 스레드가 락을 획득할 때까지 대기하는 것을 **스핀 대기(spin-wait)** 라고 하며, CPU 자원을 계속 사용하며 바쁘게 대기한다고 해서 **바쁜 대기(busy-wait)** 라고도 한다.
- 스핀 락 방식은 **아주 짧은 CPU 연산을 수행하는 임계 영역을 보호할 때만 효율적**이며, 잘못 사용하면 오히려 CPU 자원을 더 많이 소모할 수 있다.
- 스핀 락은 **락을 획득하기 위해 자원을 소모하며 반복적으로 확인하는 락 메커니즘**을 의미하며, 이러한 **스핀 락은 CAS를 사용해서 구현**할 수 있다.
